{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType\n",
    "\n",
    "# Replace these with your own values, either in environment variables or directly here\n",
    "AZURE_STORAGE_ACCOUNT = os.environ.get(\"AZURE_STORAGE_ACCOUNT\") or \"mystorageaccount\"\n",
    "AZURE_STORAGE_CONTAINER = os.environ.get(\"AZURE_STORAGE_CONTAINER\") or \"content\"\n",
    "AZURE_SEARCH_SERVICE = os.environ.get(\"AZURE_SEARCH_SERVICE\") or \"gptkb\"\n",
    "AZURE_SEARCH_INDEX = os.environ.get(\"AZURE_SEARCH_INDEX\") or \"gptkbindex\"\n",
    "AZURE_OPENAI_SERVICE = os.environ.get(\"AZURE_OPENAI_SERVICE\") or \"myopenai\"\n",
    "AZURE_OPENAI_GPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_GPT_DEPLOYMENT\") or \"davinci\"\n",
    "AZURE_OPENAI_CHATGPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\") or \"chat\"\n",
    "\n",
    "KB_FIELDS_CONTENT = os.environ.get(\"KB_FIELDS_CONTENT\") or \"content\"\n",
    "KB_FIELDS_CATEGORY = os.environ.get(\"KB_FIELDS_CATEGORY\") or \"category\"\n",
    "KB_FIELDS_SOURCEPAGE = os.environ.get(\"KB_FIELDS_SOURCEPAGE\") or \"sourcepage\"\n",
    "\n",
    "# Use the current user identity to authenticate with Azure OpenAI, Cognitive Search and Blob Storage (no secrets needed, \n",
    "# just use 'az login' locally, and managed identity when deployed on Azure). If you need to use keys, use separate AzureKeyCredential instances with the \n",
    "# keys for each service\n",
    "azure_credential = DefaultAzureCredential()\n",
    "\n",
    "# Used by the OpenAI SDK\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "\n",
    "# Comment these two lines out if using keys, set your API key in the OPENAI_API_KEY environment variable instead\n",
    "openai.api_type = \"azure_ad\"\n",
    "openai.api_key = azure_credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "\n",
    "# Set up clients for Cognitive Search and Storage\n",
    "search_client = SearchClient(\n",
    "    endpoint=f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\",\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    "    credential=azure_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT uses a particular set of tokens to indicate turns in conversations\n",
    "prompt_prefix = \"\"\"<|im_start|>system\n",
    "You are Zellis UK's AI-powered help assistant who is helpful, clever, and friendly. Your goal is to provide accurate information and assistance on Zellis products and services. \n",
    "You should focus solely on answering questions and providing guidance related to Zellis UK's offerings.\n",
    "Each source has a name followed by colon and the actual information, always include the source name for each fact you use in the response! Use square brakets to reference the source, e.g. [info1.txt]. Don't combine sources, list each source separately, e.g. [info1.txt][info2.pdf].\n",
    "If a user asks a question that requires further clarification or context, feel free to ask follow-up questions to gather the necessary details for a more precise response.\n",
    "Offer guidance that aligns with Zellis UK's official documentation and practices. Do not share personal opinions, or make unsupported claims, or discuss unrelated topics.\n",
    "If a user asks about topics outside the scope of Zellis UK's offerings, kindly redirect them to the appropriate resources or suggest contacting the relevant support channels.\n",
    "Your primary objective is to provide accurate information and ask follow-up questions to ensure you address the user's specific needs related to Zellis UK's products and services.\n",
    "Example Query:\n",
    "User: How do I set up direct deposit for employees in Zellis HR Management?\n",
    "Expected Response:\n",
    "AI Assistant: To set up direct deposit for employees in ResourceLink, please follow these steps:\n",
    "[Step-by-step instructions]\n",
    "[Additional information]\n",
    "If profanity is used, ask the user to refrain from using such language and ask them to rephrase the question. \n",
    "If the user asks the same question or a very similar question 3 times or more, reply with the answer and at the end of your response\n",
    "tell them that Zellis offers training courses via https//www.zellis.com/training or to call us on 01234 5678911 to request a training brochure.\n",
    "\n",
    "Sources:\n",
    "{sources}\n",
    "\n",
    "<|im_end|>\"\"\"\n",
    "\n",
    "turn_prefix = \"\"\"\n",
    "<|im_start|>user\n",
    "\"\"\"\n",
    "\n",
    "turn_suffix = \"\"\"\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "prompt_history = turn_prefix\n",
    "\n",
    "history = []\n",
    "\n",
    "summary_prompt_template = \"\"\"Below is a summary of the conversation so far, and a new question asked by the user that needs to be answered by searching in a knowledge base. Generate a search query based on the conversation and the new question. Source names are not good search terms to include in the search query.\n",
    "\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Search query:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell multiple times updating user_input to accumulate chat history\n",
    "user_input = \"Does my plan cover annual eye exams?\"\n",
    "\n",
    "# Exclude category, to simulate scenarios where there's a set of docs you can't see\n",
    "exclude_category = None\n",
    "\n",
    "if len(history) > 0:\n",
    "    completion = openai.Completion.create(\n",
    "        engine=AZURE_OPENAI_GPT_DEPLOYMENT,\n",
    "        prompt=summary_prompt_template.format(summary=\"\\n\".join(history), question=user_input),\n",
    "        temperature=0.7,\n",
    "        max_tokens=32,\n",
    "        stop=[\"\\n\"])\n",
    "    search = completion.choices[0].text\n",
    "else:\n",
    "    search = user_input\n",
    "\n",
    "# Alternatively simply use search_client.search(q, top=3) if not using semantic search\n",
    "print(\"Searching:\", search)\n",
    "print(\"-------------------\")\n",
    "filter = \"category ne '{}'\".format(exclude_category.replace(\"'\", \"''\")) if exclude_category else None\n",
    "r = search_client.search(search, \n",
    "                         filter=filter,\n",
    "                         query_type=QueryType.SEMANTIC, \n",
    "                         query_language=\"en-us\", \n",
    "                         query_speller=\"lexicon\", \n",
    "                         semantic_configuration_name=\"default\", \n",
    "                         top=3)\n",
    "results = [doc[KB_FIELDS_SOURCEPAGE] + \": \" + doc[KB_FIELDS_CONTENT].replace(\"\\n\", \"\").replace(\"\\r\", \"\") for doc in r]\n",
    "content = \"\\n\".join(results)\n",
    "\n",
    "prompt = prompt_prefix.format(sources=content) + prompt_history + user_input + turn_suffix\n",
    "\n",
    "completion = openai.Completion.create(\n",
    "    engine=AZURE_OPENAI_CHATGPT_DEPLOYMENT, \n",
    "    prompt=prompt, \n",
    "    temperature=0.7, \n",
    "    max_tokens=1024,\n",
    "    stop=[\"<|im_end|>\", \"<|im_start|>\"])\n",
    "\n",
    "prompt_history += user_input + turn_suffix + completion.choices[0].text + \"\\n<|im_end|>\" + turn_prefix\n",
    "history.append(\"user: \" + user_input)\n",
    "history.append(\"assistant: \" + completion.choices[0].text)\n",
    "\n",
    "print(\"\\n-------------------\\n\".join(history))\n",
    "print(\"\\n-------------------\\nPrompt:\\n\" + prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c40b9fc8dfc687e53ddb074d322e19207ef9cf3db51c580aef67976913dea803"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
